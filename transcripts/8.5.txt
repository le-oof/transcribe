New chunk:
Важаемый слушателем. На данной лекции мы закончим рассмотрение философских проблем искусственного интеллекта. Используя понятия интенсиональности, которые мы рассмотрели на прошлой лекции, обсудим вопросы синтоксиса и симантики искусственного интеллекта. Определим понятия. Синтоксис – это теория знаковой системы, определяющая правила использования знаков в том или ином языке. Симантика – это теория о значении знаков. Оргумент китайской комната Джона Сёрла утверждает то, что язык искусственных систем не имеет
New chunk:
Джона Сёрлова утверждает то, что язык искусственных систем не имеет симантики. Все работа в системе интерфейса человек-компьютер со стороны машины происходит исключительно на синтоксическом уровне. Компьютер обучен определенным программом алгоритмом связи символических элементов знаковой системы, так, что возникает впечатление относительно их симантической нагруженности. Возьмем в качестве примера работа у географической электронной инциклопедии. Техническая система запрограммирована так, чтобы получив от человека запрос, как называется столица не пала, выдавать ответа к отманду. При этом очевидно, что компьютер не понимает, что собственно стоит за теми знаками языка, которые использованы в данном запросе. Симантический, а не для него пусто.
New chunk:
языка, который использованы в данном запросе, семантические они для него пусты. Просто в соответствующей программе дана директива, при запросе, представляющим собой один синтексический комплекс, выдавать в качестве ответа другой. Машина может действовать как формальный логик. Отвлекаясь от какого-либо содержательного наполнения, она способна к отценке истинности сложных высказнований на основании анализа истинных функций, составляющих их простых высказываний. Однако это дедуктивная ловкость машины будет только подтверждать тезис Джона Сёрлова. В работе компьютера нас завораживает именно это невероятная синтексическая мощь, скорость оперирования знаками. Тем не менее, какими бы головокружительными ни были операции, связанные с синтексисом формулам.
New chunk:
Какими бы головокружительными ни были операции, связанные с синтоксисом формальной знаковой системы, компьютер никогда не сможет самостоятельно задать им какую-либо симантическую интерпретацию. Оргумент китайской комнаты вызвал бурные обсуждения в рамках традиции философии искусственного интеллекта. Интересный момент выследования данной проблемы, на которых хотелось бы обратить внимание в этой теме, заключается в том, что спустя 10 лет, тот же Джон Сьору, весьма оригинальным образом пересмотрел свой собственный аргумент. На этот раз вопрос был поставлен осень токсиси. А можем ли ему утверждать, так как мы это делали ранее, что машина способна на выполнение синтоксических процедур в рамках заданной знаковой системы. Теперь американский философии
New chunk:
в рамках заданной знаковый систем. Теперь американский философ дал отрицательный ответ и на этот вопрос. Для того, чтобы прояснить смысл сёрлевской аргументации, вновь вспомним для начала англичанина изучающего китайский. Тречический аргумент относительно симантики начинался с того, что человек не понимает значение написанных на бумаге символов. Освавивая формальная правила операции с данными символами, он влудивает определенной синтоксической техникой, которая создает иллюзию симантической осведомленности. Однако не пропустилили мы здесь при описании данного линвистического действия одного важного момента, на которой нам следовало бы обратить внимание ещё до начала формулировки критического аргумента относительно симантики.
New chunk:
еще до начала формулировки критического аргумента относительно симантики. Что именно может увидеть человек на предоставленных в его распоряжении листах бумаги? Стро говоря, на физическом уровне на листе бумаги виден лишь хаотический набор чернельных пятин различной формы. Получается, что прежде чем констатировать свою неосведомленность относительно симантики языка. Человек из китайской комнаты уже должен задать определенную синтоксическую интерпретацию. Он должен понять вот эти чернельные пятна на листе бумаги именно как знаки, которые, возможно, объединены какой-либо системой правил функционирования, составляя при этом единая целая языка.
New chunk:
составляя при этом единственное целое язык. На одной из прошлых лекций мы уже обсудили вопрос о том, что в основании информатики была положена, по сути, простая идея объединения математической логики и электричества. К тому времени 30-ый года 20-го века, в логике уже прочно зарекомендовал себя новый подход, основанный наслияние формально логической символики и языка математики. Идеи информатики заключались в том, что было предложено интерпретировать наличие или отсутствие напряжения в электрической цепи, как знаки математических символов и единица и ноль соответствами. Так возникается фравой компьютер. Но составляют ли мантематические символы и единица и ноль синтоксис машины? То есть действие
New chunk:
символы 1 и 0 синтоксис машины. То есть действительно ли железа компьютера это на граммождение 0 и 1. Джон Сёрл дает отрицательный ответ на этот вопрос. Дело в том, что физика не имеет синтоксису вообще. Наличие напряжения в электрической цепи это еще не 1. Это лишь наличие напряжения в электрической цепи. Приставим ситуацию, что мы вкручиваем лампочку в патрон настольной лампы с плохим качеством контакта проводников тока. Лампочка то загорается, то гаснет. Будем ли мы считать данные события физического уровня передачей скажем какого-либо зашифрованного кода. В данном случае конечно же нет. В этом как раз и состоит родственная любовьがkum pledа. Чел chantant
New chunk:
В данном случае, конечно же, нет. В этом как раз и состоит первичный интерпретативный шаг. Понять определенный уровень электрического напряжения как знак. И пока не важно знак чего, логического референта, или скажем предупреждения об опасности пожара. Физический уровень в качестве материального носителя, языковых выражений, прежде симантической, должен в начале получить синтоксическую интерпретацию, которая задается внешним образом, через пользователи данной знаковой системы. Если при использовании электронной encyclopedia, я задаю вопрос о столице не Пала и получаю на лежащий ответ, то машина не только не понимает значение символов, с которыми она оперируется ответственно и сопределенным алгоритмом. Она не представляется бы даже и ф...
New chunk:
оперируется ответственность соприделенному алгоритмам. Она не представляется бы даже и формальную синтоксическую систему. На физическом уровне в след за одним случае высокого уровня напряжения в определенном участке цепи возникает другой случай, только и всего. Для того, чтобы эти факты высокого напряжения понять, как знаки, которые могут подчиняться определенным, операциональным правилам их сочетания, необходимо задать первичную синтоксическую интерпретацию, на которую в дальнейшем и будет операться программист при формулировке соответствующего алгоритма операции. На основании изложенного материала последних трех лекций мы можем заключить, что невозможно получить однозначный ответ на вопрос о том, является ли существующие на сегодняшний день технические системы, действительно интеллектурует.
New chunk:
являются ли существующие на сегодняшний день технические системы, действительно интеллектуальными в смысле сильного искусственного интеллекта. Ответ на данный вопрос будет зависеть от системы отчетов, которые мы работаем, то есть от той парадигной понимания интеллектуальной деятельности, которую мы выбираем. В этих условиях весьма полезным, ввиду свои простоты выступают так называемый тест тьюринга на определение интеллектуальности технической системы. Обсуждением этой разработки закончим наши рассмотрения философских проблем искусственного интеллекта. Аландсьюринг, английский математик и инженер. Один из основоположников информатики стоял у истоков теории и практического развития компьютерной техники. В точке зрения теста тьюринга, мы должны исходить из
New chunk:
компьютерной техники. В точке зрения теста Чюринга мы должны исходить из бихивеористских позиций при исследовании интеллекта. Бихивеоризм от английского бихеева поведения, направление в психологии изучающие мышления с точки зрения поведения частей реакции человека. Бихивеоризм рассматривает сознание в качестве так называемого черного ящика. Мы знаем, что условно подается на вход этого устройства и мы знаем, что имеем на выходе, но просто перестаем задавать вопрос о том, что происходит внутри него. Тем самым все сложные вопросы с определением того, как именно на физическом и на психическом уровне. Функционировать человеческий разум оказывается в ней рассмотрение. Мы обсуждаем только внешнее проявление человека. Мы задаем ему ваше...
New chunk:
рассмотрением. Мы обсуждаем только внешнее проявление человека. Мы задаем ему вопросы и фиксируем его реакцию, то есть слушаем ответы, наблюдаем за его действиями. Точно так же тьюринг предложил оценивать и работу системы искусственного интеллекта. Главный тезис его теста гласит следующие. Если по внешним признакам своей деятельности машина демонстрирует своё подобие деятельности человека, то вне зависимости от того, что происходит внутри машины, будем считать её поведение разумным. Проще говоря, если ответы машины на поставленные вопросы, невозможно отличить от ответов, которые на эти же вопросы давал бы человек, то следует считать, что машина проходит тест на интеллектуальность. Например, если на вопрос...
New chunk:
тест на интеллектуальность. Например, если на вопрос сколько будет 2 плюс 2 машина выдаёт ответ 4, будем считать это разумным ответом. Очевидно, что при решении арифметических задач электроновучислительные машины легко проходят тест юринга. Однако при постановке более сложных вопросов, где четкой алгоритмизации действий добиться на многоторгнее, прохождение теста юлингам не простая задача.
